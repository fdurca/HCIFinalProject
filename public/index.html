<!doctype html>

<html lang="en">
<head>
  <title>Understanding Convolutions on Graphs</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=1200">
  <script src="https://distill.pub/template.v2.js"></script>
  <style id="distill-article-specific-styles">
    .subgrid {
  grid-column: screen; 
  display: grid; 
  grid-template-columns: inherit;
  grid-template-rows: inherit;
  grid-column-gap: inherit;
  grid-row-gap: inherit;
}

d-figure.base-grid {
  grid-column: screen;
  background: hsl(0, 0%, 97%);
  padding: 20px 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

d-figure {
  margin-bottom: 1em;
  position: relative;
}

d-figure > figure {
  margin-top: 0;
  margin-bottom: 0;
}

.shaded-figure {
  background-color: hsl(0, 0%, 97%);
  border-top: 1px solid hsla(0, 0%, 0%, 0.1);
  border-bottom: 1px solid hsla(0, 0%, 0%, 0.1);
  padding: 30px 0;
}

.pointer {
  position: absolute;
  width: 26px;
  height: 26px;
  top: 26px;
  left: -48px;
}

div#observablehq {
  font-family: inherit;
  font-size: inherit;
}

button {
  font-family : inherit;
  font-size: 1em;
}

/* Alignment of KaTeX. */
#gnn-models span.katex-display {
  margin: 0.5em 0 0.5em 0em;
}

@media (max-width: 1000px) {
  d-contents {
    justify-self: start;
    align-self: start;
    grid-column-start: 2;
    grid-column-end: 6;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom-width: 1px;
    border-bottom-style: solid;
    border-bottom-color: rgba(0, 0, 0, 0.1);
  }
}

@media (min-width: 1000px) {
  d-contents {
    align-self: start;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: end;
    padding-right: 3em;
    padding-left: 2em;
    border-right: 1px solid rgba(0, 0, 0, 0.1);
    border-right-width: 1px;
    border-right-style: solid;
    border-right-color: rgba(0, 0, 0, 0.1);
  }
}

@media (min-width: 1180px) {
  d-contents {
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: end;
    padding-right: 3em;
    padding-left: 2em;
    border-right: 1px solid rgba(0, 0, 0, 0.1);
    border-right-width: 1px;
    border-right-style: solid;
    border-right-color: rgba(0, 0, 0, 0.1);
  }
}

d-contents nav h3 {
  margin-top: 0;
  margin-bottom: 1em;
}

d-contents nav a {
  color: rgba(0, 0, 0, 0.8);
  border-bottom: none;
  text-decoration: none;
}

d-contents li {
  list-style-type: none;
}

d-contents ul {
  padding-left: 1em;
}

d-contents nav ul li {
  margin-bottom: 0.25em;
}

d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6);
}

d-contents nav ul {
  margin-top: 0;
  margin-bottom: 6px;
}

d-contents nav > div {
  display: block;
  outline: none;
  margin-bottom: 0.5em;
}

d-contents nav > div > a {
  font-size: 13px;
  font-weight: 600;
}

d-contents nav > div > a:hover, d-contents nav > ul > li > a:hover {
  text-decoration: none;
}

input[type="radio"] {
  vertical-align: unset !important;
}

.math-details {
  padding-left: 1em;
  padding-right: 1em;
  padding-bottom: 0em;
  padding-top: 1em;
  margin-bottom: 1em;
}
  </style>
</head>

<body>
  
  <d-front-matter>
    <script type="text/json">
      {
    "title": "Understanding Convolutions on Graphs",
    "description": "Understanding the building blocks and design choices of graph neural networks.",
    "authors": [
        {
            "author": "Ameya Daigavane",
            "authorURL": "https://ameya98.github.io/",
            "affiliation": "Google Research",
            "affiliationURL": "https://research.google/"
        },
        {
            "author": "Balaraman Ravindran",
            "authorURL": "https://www.cse.iitm.ac.in/~ravi/",
            "affiliation": "Google Research",
            "affiliationURL": "https://research.google/"
        },
        {
            "author": "Gaurav Aggarwal",
            "authorURL": "https://research.google/people/GauravAggarwal/",
            "affiliation": "Google Research",
            "affiliationURL": "https://research.google/"
        }
    ],
    "katex": {
        "delimiters": [
            {
                "left": "$",
                "right": "$",
                "display": false
            },
            {
                "left": "$$",
                "right": "$$",
                "display": true
            }
        ]
    }
}
    </script>
  </d-front-matter>

  <d-title>
    <h1>Understanding Convolutions on Graphs</h1>
    <p>Understanding the building blocks and design choices of graph neural networks.</p>
  </d-title>

  <d-article>
    <d-contents>
      <nav class="l-text figcaption">
        <h3>Contents</h3>
        <div><a href="#introduction">Introduction</a></div>
        <div><a href="#challenges">The Challenges of Computation on Graphs</a></div>
        <ul>
          <li><a href="#lack-of-consistent-structure">Lack of Consistent Structure</a></li>
          <li><a href="#node-order">Node-Order Equivariance</a></li>
          <li><a href="#scalability">Scalability</a></li>
        </ul>
        <div><a href="#problem-and-notation">Problem Setting and Notation</a></div>
        <div><a href="#extending">Extending Convolutions to Graphs</a></div>
        <div><a href="#polynomial-filters">Polynomial Filters on Graphs</a></div>
        <div><a href="#modern-gnns">Modern Graph Neural Networks</a></div>
        <div><a href="#interactive">Interactive Graph Neural Networks</a></div>
        <div><a href="#from-local-to-global">From Local to Global Convolutions</a></div>
        <ul>
          <li><a href="#spectral">Spectral Convolutions</a></li>
          <li><a href="#graph-embeddings">Global Propagation via Graph Embeddings</a></li>
        </ul>
        <div><a href="#learning">Learning GNN Parameters</a></div>
        <!-- <div><a href="#gnns-vs-cnns">Are GNNs 'better' than CNNs?</a></div> -->
        <div><a href="#further-reading">Conclusions and Further Reading</a></div>
        <ul>
          <li><a href="#practical-techniques">GNNs in Practice</a></li>
          <li><a href="#different-kinds-of-graphs">Different Kinds of Graphs</a></li>
          <li><a href="#pooling">Pooling</a></li>
        </ul>
        <div><a href="#supplementary">Supplementary Material</a></div>
        <ul>
          <li><a href="#experiments-notebooks">Reproducing Experiments</a></li>
          <li><a href="#visualizations-notebooks">Recreating Visualizations</a></li>
        </ul>
      </nav>
    </d-contents>
    <div>
      <p><em>
        This article is one of two Distill publications about graph neural networks.
        Take a look at
        <a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</a>
        <d-cite key="gnn-intro"></d-cite>
        for a companion view on many things graph and neural network related.
      </em></p>
      <p id="introduction">
        Many systems and interactions - social networks, molecules, organizations, citations, physical models, transactions - can be represented quite naturally as graphs.
        How can we reason about and make predictions within these systems?
      </p>
      <p>
        One idea is to look at tools that have worked well in other domains: neural networks have shown immense predictive power in a variety of learning tasks.
        However, neural networks have been traditionally used to operate on fixed-size and/or regular-structured inputs (such as sentences, images and video).
        This makes them unable to elegantly process graph-structured data.
      </p>
      <figure id="standard-neural-networks" class="l-page">
        <img src="images/standard-neural-networks.svg" style="width: 100%;"
             alt="Neural networks generally operate on fixed-size input vectors. How do we input a graph to a neural network?"
             title="How do we input a graph to a neural network?">
      </figure>
    </div>
    
    <p>
      Graph neural networks (GNNs) are a family of neural networks that can operate naturally on graph-structured data. 
      By extracting and utilizing features from the underlying graph,
      GNNs can make more informed predictions about entities in these interactions,
      as compared to models that consider individual entities in isolation.
    </p>
    <p>
      GNNs are not the only tools available to model graph-structured data:
      graph kernels <d-cite key="graph-kernels"></d-cite>
      and random-walk methods <d-cite key="node2vec,deepwalk"></d-cite>
      were some of the most popular ones.
      Today, however, GNNs have largely replaced these techniques
      because of their inherent flexibility to model the underlying systems
      better.
    </p>
    <p>
      In this article, we will illustrate
      the challenges of computing over graphs, 
      describe the origin and design of graph neural networks,
      and explore the most popular GNN variants in recent times.
      Particularly, we will see that many of these variants
      are composed of similar building blocks.
    </p>
    <p>
      First, let's discuss some of the complications that graphs come with.
    </p>

    <h2 id="challenges">
      The Challenges of Computation on Graphs
    </h2>

    <h3 id="lack-of-consistent-structure">
      Lack of Consistent Structure
    </h3>
      <p>
        Graphs are extremely flexible mathematical models; but this means they lack consistent structure across instances.
        Consider the task of predicting whether a given chemical molecule is toxic <d-cite key="molecules-gnn,neural-message-passing"></d-cite> :
      </p>
      <figure class="l-page-outset" id="menthyl-nicotinate-molecule" style="display: inline-flex;">
        <img src="images/1,2,6-trigalloyl-glucose-molecule.svg" style="width: 50%;"
             alt="The molecular structure of non-toxic 1,2,6-trigalloyl-glucose.">
        <img src="images/caramboxin-molecule.svg" style="width: 25%; height: 60%; margin-top: 8%; margin-left: 10%;"
             alt="The molecular structure of toxic caramboxin.">
      </figure>
      <figure class="l-page-outset" style="display: flex; margin-top: 0%; margin-bottom: 3%;">
        <figure style="width: 50%; margin-left: 1%; margin-bottom: 0%;">
          <figcaption><b>Left:</b> A <span style="color: green;">non-toxic</span> 1,2,6-trigalloyl-glucose molecule.</figcaption>
        </figure>
        <figure style="width: 50%; margin-right: 15%; margin-bottom: 0%; text-align: right;">
          <figcaption><b>Right:</b> A <span style="color: rgba(228, 35, 35, 0.911);">toxic</span> caramboxin molecule.</figcaption>
        </figure>
      </figure>
      <p>
        Looking at a few examples, the following issues quickly become apparent:
      </p>
      <ul>
        <li>Molecules may have different numbers of atoms.</li>
        <li>The atoms in a molecule may be of different types.</li>
        <li>Each of these atoms may have different number of connections.</li>
        <li>These connections can have different strengths.</li>
      </ul>
      <p>
        Representing graphs in a format that can be computed over is non-trivial,
        and the final representation chosen often depends significantly on the actual problem.
      </p>

    <h3 id="node-order">
      Node-Order Equivariance
    </h3>
    <p>
      Extending the point above: graphs often have no inherent ordering present amongst the nodes.
      Compare this to images, where every pixel is uniquely determined by its absolute position within the image!
    </p>

      <figure id="node-order-alternatives" class="l-page" style="margin-bottom: 1em;">
        <img src="images/node-order-alternatives.svg" style="margin-bottom: 1em; margin-left: 15%; width: 70%;"
             alt="Representing the graph as one vector requires us to fix an order on the nodes. But what do we do when the nodes have no inherent order?">
        <figcaption style="text-align: center; margin-left: 10%; width: 80%;">
          Representing the graph as one vector requires us to fix an order on the nodes.
          But what do we do when the nodes have no inherent order?
          <b>Above:</b> 
          The same graph labelled in two different ways. The alphabets indicate the ordering of the nodes.
        </figcaption>
      </figure>
  
    <p>
      As a result, we would like our algorithms to be node-order equivariant:
      they should not depend on the ordering of the nodes of the graph.
      If we permute the nodes in some way, the resulting representations of 
      the nodes as computed by our algorithms should also be permuted in the same way.
    </p>

    <h3 id="scalability">
      Scalability
    </h3>
      <p>
        Graphs can be really large! Think about social networks like Facebook and Twitter, which have over a billion users. 
        Operating on data this large is not easy.
      </p>
      <p>
        Luckily, most naturally occuring graphs are 'sparse':
        they tend to have their number of edges linear in their number of vertices.
        We will see that this allows the use of clever methods
        to efficiently compute representations of nodes within the graph.
        Further, the methods that we look at here will have significantly fewer parameters
        in comparison to the size of the graphs they operate on.
      </p>

    <h2 id="problem-and-notation">
      Problem Setting and Notation
    </h2>
      <p>
        There are many useful problems that can be formulated over graphs:
      </p>
        <ul>
          <li><b>Node Classification:</b> Classifying individual nodes.</li>
          <li><b>Graph Classification:</b> Classifying entire graphs. </li>
          <li><b>Node Clustering:</b> Grouping together similar nodes based on connectivity.</li>
          <li><b>Link Prediction:</b> Predicting missing links.</li>
          <li><b>Influence Maximization:</b> Identifying influential nodes.</li>
        </ul>
      <figure id="graph-tasks" class="l-page">
        <img src="images/graph-tasks.svg" style="width: 100%;"
             alt="Examples of problems that can be defined over graphs.">
        <figcaption style="text-align: center;">
          Examples of problems that can be defined over graphs.
          This list is not exhaustive!
        </figcaption>
      </figure>
      <p>
        A common precursor in solving many of these problems is <b>node representation learning</b>:
        learning to map individual nodes to fixed-size real-valued vectors (called 'representations' or 'embeddings').
      </p>
      <p>
        In <a href="#learning">Learning GNN Parameters</a>, we will see how the learnt embeddings can be used for these tasks.
      </p>
      <p>
        Different GNN variants are distinguished by the way these representations are computed.
        Generally, however, GNNs compute node representations in an iterative process.
        We will use the notation $h_v^{(k)}$ to indicate the representation of node $v$ after the $k^{\text{th}}$ iteration.
        Each iteration can be thought of as the equivalent of a 'layer' in standard neural networks.
      </p>
      <p>
        We will define a graph $G$ as a set of nodes, $V$, with a set of edges $E$ connecting them.
        Nodes can have individual features as part of the input: we will denote by $x_v$ the individual feature for node $v \in V$.
        For example, the 'node features' for a pixel in a color image
        would be the red, green and blue channel (RGB) values at that pixel.
      </p>
      <p>
        For ease of exposition, we will assume $G$ is undirected, and all nodes are of the same type.
        <d-footnote>These kinds of graphs are called 'homogeneous'.</d-footnote>
        Many of the same ideas we will see here 
        apply to other kinds of graphs:
        we will discuss this later in <a href="#different-kinds-of-graphs">Different Kinds of Graphs</a>.
      </p>
      <p>
        Sometimes we will need to denote a graph property by a matrix $M$,
        where each row $M_v$ represents a property corresponding to a particular vertex $v$.
      </p>

    <h2 id="extending">
      Extending Convolutions to Graphs
    </h2>
    <p>
      Convolutional Neural Networks have been seen to be quite powerful in extracting features from images.
      However, images themselves can be seen as graphs with a very regular grid-like structure,
      where the individual pixels are nodes, and the RGB channel values at each pixel as the node features.
    </p>
    <p>
      A natural idea, then, is to consider generalizing convolutions to arbitrary graphs. Recall, however, the challenges
      listed out in the <a href="#challenges">previous section</a>: in particular, ordinary convolutions are not node-order invariant, because
      they depend on the absolute positions of pixels.
      It is initially unclear as how to generalize convolutions over grids to convolutions over general graphs,
      where the neighbourhood structure differs from node to node.
      <d-footnote>
        The curious reader may wonder if performing some sort of padding and ordering
        could be done to ensure the consistency of neighbourhood structure across nodes.
        This has been attempted with some success <d-cite key="patchysan"></d-cite>,
        but the techniques we will look at here are more general and powerful.
      </d-footnote>
    </p>
    
    <figure id="cnns-vs-gnns-neigh" class="l-page" style="display: flex; align-items: center; flex-direction: column;">
      <div id="observablehq-cnn_svg-35509536"
        role="img" aria-label="GNNs can perform localized convolutions, similar to those in CNNs."
        style="text-align: center;"></div>
      <figure style="position: relative; text-align: center; margin-top: 0; width: 30%;">
        <figcaption>
          Convolutions in CNNs are inherently localized.
          Neighbours participating in the convolution at the center pixel are highlighted in gray.
        </figcaption>
      </figure>
      <div id="observablehq-svg-35509536"
        style="text-align: center;"></div>
      <figure style="position: relative; text-align: center; margin-top: 1%; width: 40%;">
        <figcaption>
          GNNs can perform localized convolutions mimicking CNNs.
          Hover over a node to see its immediate neighbourhood highlighted on the left.
          The structure of this neighbourhood changes from node to node.
        </figcaption>
      </figure>

      <script type="module">
      import {Runtime, Inspector} from "./observablehq-base/runtime.js";
      import define from "./notebooks/neighbourhoods-for-cnns-and-gnns.js";
      setTimeout(() => {
        new Runtime().module(define, name => {
          if (name === "cnn_svg") return new Inspector(document.querySelector("#observablehq-cnn_svg-35509536"));
          if (name === "svg") return new Inspector(document.querySelector("#observablehq-svg-35509536"));
          return ["adjust_dimensions","reset_nodes","highlight_nodes","get_node_position","remove_old_arrows","draw_arrows_to_updated_node","add_interactivity","on_selected_node_change","updated_node_position"].includes(name);
        });
      }, 200);
      </script>
    </figure>
    <p>
      We begin by introducing the idea of constructing polynomial filters over node neighbourhoods,
      much like how CNNs compute localized filters over neighbouring pixels.
      Then, we will see how more recent approaches extend on this idea with more powerful mechanisms.
      Finally, we will discuss alternative methods
      that can use 'global' graph-level information for computing node representations.
    </p>

    <h2 id="polynomial-filters">
      Polynomial Filters on Graphs
    </h2>
      <h3 style="margin-top: 0;">
        The Graph Laplacian
      </h3>
      <p>
        Given a graph $G$, let us fix an arbitrary ordering of the $n$ nodes of $G$.
        We denote the $0-1$ adjacency matrix of $G$ by $A$, we can construct the diagonal degree matrix $D$ of $G$ as:      
      </p>
      <div style="position: relative; display: flex;">
        <d-math block>
          D_v = \sum_u A_{vu}.
        </d-math>
        <figure id="diagonal-degree-matrix">
          <figcaption style="margin-left: 15%; margin-top: -2%;">
            The degree of node $v$ is the number of edges incident at $v$.
          </figcaption>
        </figure>
      </div>
      <p>
        where $A_{vu}$ denotes the entry in the row corresponding to $v$ and the column corresponding to $u$
        in the matrix $A$. We will use this notation throughout this section.
      </p>
      <p>
        Then, the graph Laplacian $L$ is the square $n \times n$ matrix defined as:
        <d-math>
          L = D - A.
        </d-math>
      </p>
      <figure id="laplacian" class="l-page">
        <img src="images/laplacian.svg" style="margin-right: 0%; margin-left: 10%; width: 70%; margin-bottom: 1em;">
        <figcaption style="text-align: center; width: 70%; margin-left: 15%;">
          The Laplacian $L$ for an undirected graph $G$, with the row corresponding to node $\textsf{C}$ highlighted.
          Zeros in $L$ are not displayed above.
          The Laplacian $L$ depends only on the structure of the graph $G$, not on any node features.
        </figcaption>
      </figure>
      <p>
        The graph Laplacian gets its name from being the discrete analog of the
        <a href="https://mathworld.wolfram.com/Laplacian.html">Laplacian operator</a>
        from calculus.
      </p>
      <p>
        Although it encodes precisely the same information as the adjacency matrix $A$
        <d-footnote>
          In the sense that given either of the matrices $A$ or $L$, you can construct the other.
        </d-footnote>,
        the graph Laplacian has many interesting properties of its own.
        <d-footnote>
          The graph Laplacian shows up in many mathematical problems involving graphs:
          <a href="https://people.math.sc.edu/lu/talks/nankai_2014/spec_nankai_2.pdf">random walks</a>,
          <a href="https://arxiv.org/abs/0711.0189">spectral clustering</a><d-cite key="spectral-clustering"></d-cite>,
          and
          <a href="https://www.math.fsu.edu/~bertram/lectures/Diffusion.pdf">diffusion</a>, to name a few.
        </d-footnote>
        We will see some of these properties
        in <a href="#spectral">a later section</a>,
        but will instead point readers to
        <a href="https://csustan.csustan.edu/~tom/Clustering/GraphLaplacian-tutorial.pdf">this tutorial</a>
        for greater insight into the graph Laplacian.
      </p>

      <h3>
        Polynomials of the Laplacian
      </h3>
      <p>
        Now that we have understood what the graph Laplacian is,
        we can build polynomials <d-cite key="chebnet"></d-cite> of the form:
        <d-math block>
          p_w(L) = w_0 I_n + w_1 L + w_2 L^2 + \ldots + w_d L^d = \sum_{i = 0}^d w_i L^i.
        </d-math>
        Each polynomial of this form can alternately be represented by
        its vector of coefficients $w = [w_0, \ldots, w_d]$.
        Note that for every $w$, $p_w(L)$ is an $n \times n$ matrix, just like $L$.
      </p>
      <p>
        These polynomials can be thought of as the equivalent of 'filters' in CNNs,
        and the coefficients $w$ as the weights of the 'filters'.
      </p>
      <p>
        For ease of exposition, we will focus on the case where nodes have one-dimensional features:
        each of the $x_v$ for $v \in V$ is just a real number. 
        The same ideas hold when each of the $x_v$ are higher-dimensional vectors, as well.
      </p>
      <p>
        Using the previously chosen ordering of the nodes,
        we can stack all of the node features $x_v$
        to get a vector $x \in \mathbb{R}^n$.
      </p>
      <figure id="node-order-vector" class="l-body">
        <img src="images/node-order-vector.svg" style="margin-right: 10%; margin-left: 10%; margin-bottom: 1%; width: 80%;"
              alt="Fixing a node order and collecting all node features into a single vector.">
        <figcaption style="text-align: center;">
          Fixing a node order (indicated by the alphabets) and collecting all node features into a single vector $x$.
        </figcaption>
      </figure>
      <p>
        Once we have constructed the feature vector $x$,
        we can define its convolution with a polynomial filter $p_w$ as:
        <d-math block>
          x' = p_w(L) \ x
        </d-math>
        To understand how the coefficients $w$ affect the convolution,
        let us begin by considering the 'simplest' polynomial:
        when $w_0 = 1$ and all of the other coefficients are $0$.
        In this case, $x'$ is just $x$:
        <d-math block>
          x' = p_w(L) \ x = \sum_{i = 0}^d w_i L^ix = w_0 I_n x = x.
        </d-math>
        Now, if we increase the degree, and consider the case where
        instead $w_1 = 1$ and and all of the other coefficients are $0$.
        Then, $x'$ is just $Lx$, and so:
        <d-math block>
          \begin{aligned}
           x'_v = (Lx)_v &= L_v x \\ 
                         &= \sum_{u \in G} L_{vu} x_u \\ 
                         &= \sum_{u \in G} (D_{vu} - A_{vu}) x_u \\ 
                         &= D_v \ x_v - \sum_{u \in \mathcal{N}(v)} x_u
          \end{aligned}
        </d-math>
        We see that the features at each node $v$ are combined
        with the features of its immediate neighbours $u \in \mathcal{N}(v)$.
        <d-footnote>
          For readers familiar with
          <a href="https://docs.opencv.org/3.4/d5/db5/tutorial_laplace_operator.html">Laplacian filtering of images</a>,
          this is the exact same idea. When $x$ is an image, 
          $x' = Lx$ is exactly the result of applying a 'Laplacian filter' to $x$.
        </d-footnote>
      </p>
      <p>
        At this point, a natural question to ask is:
        How does the degree $d$ of the polynomial influence the behaviour of the convolution?
        Indeed, it is not too hard to show that:
        <d-footnote>This is Lemma 5.2 from <d-cite key="wavelets-graphs"></d-cite>.</d-footnote>
        <d-math block>
          \text{dist}_G(v, u) > i \quad \Longrightarrow \quad L_{vu}^i = 0.
        </d-math>
      
        This implies, when we convolve $x$ with $p_w(L)$ of degree $d$ to get $x'$:
        <d-math block>
          \begin{aligned}
          x'_v = (p_w(L)x)_v  &= (p_w(L))_v x \\
              &= \sum_{i = 0}^d w_i L_v^i x \\
              &= \sum_{i = 0}^d w_i \sum_{u \in G} L_{vu}^i x_u \\
              &= \sum_{i = 0}^d w_i \sum_{u \in G \atop \text{dist}_G(v, u) \leq i} L_{vu}^i x_u.
          \end{aligned}
        </d-math>
      <p>
        Effectively, the convolution at node $v$ occurs only with nodes $u$ which are not more than $d$ hops away.
        Thus, these polynomial filters are localized. The degree of the localization is governed completely by $d$.
      </p>
      <p>
        To help you understand these 'polynomial-based' convolutions better, we have created the visualization below.
        Vary the polynomial coefficients and the input grid $x$ to see how the result $x'$ of the convolution changes.
        The grid under the arrow shows the equivalent convolutional kernel applied at the highlighted pixel in $x$ to get
        the resulting pixel in $x'$.
        The kernel corresponds to the row of $p_w(L)$ for the highlighted pixel.
        Note that even after adjusting for position,
        this kernel is different for different pixels, depending on their position within the grid.
      </p>
        <div class="shaded-figure l-screen" id="polynomial-convolutions" style="grid-column: page;"
          role="img" aria-label="An interactive visualization showing polynomial convolutions on an input grid.">
          <div id="observablehq-grid_buttons_display-05850d43" style="margin-bottom: 1em;"></div>
          <div id="observablehq-poly_color_scale-05850d43" style="display: flex; justify-content: center; margin-bottom: 30px;"></div>
          <div id="observablehq-poly_figcaptions-05850d43" style="position: relative; top: -50px;"></div>
          <div id="observablehq-poly_conv_main_div-05850d43"></div>
          <div id="observablehq-polynomial_display-05850d43" style="margin-top: 2em;"></div>
          <div id="observablehq-poly_conv_sliders-05850d43"></div>
          <div id="observablehq-viewof-laplacian_type-05850d43" style="text-align: center; margin-top: 2em;"></div>
          <div id="observablehq-reset_coeffs_button_display-05850d43" style="margin-top: 25px; margin-bottom: 0;"></div>
          <div id="observablehq-poly_input_slider_watch-05850d43" style="display: none;"></div>
          <div id="observablehq-highlight_selected_cell-05850d43" style="display: none;"></div>
          <!-- <p>Credit: <a href="https://observablehq.com/@ameyasd/cleaner-interactive-graph-polynomial-convolutions">Interactive Graph Polynomial Convolutions by Ameya Daigavane</a></p> -->

          <script type="module">
          import {Runtime, Inspector} from "./observablehq-base/runtime.js";
          import define from "./notebooks/cleaner-interactive-graph-polynomial-convolutions.js";
          setTimeout(() => {
            new Runtime().module(define, name => {
              if (name === "grid_buttons_display") return new Inspector(document.querySelector("#observablehq-grid_buttons_display-05850d43"));
              if (name === "poly_color_scale") return new Inspector(document.querySelector("#observablehq-poly_color_scale-05850d43"));
              if (name === "poly_figcaptions") return new Inspector(document.querySelector("#observablehq-poly_figcaptions-05850d43"));
              if (name === "poly_conv_main_div") return new Inspector(document.querySelector("#observablehq-poly_conv_main_div-05850d43"));
              if (name === "viewof laplacian_type") return new Inspector(document.querySelector("#observablehq-viewof-laplacian_type-05850d43"));
              if (name === "polynomial_display") return new Inspector(document.querySelector("#observablehq-polynomial_display-05850d43"));
              if (name === "poly_conv_sliders") return new Inspector(document.querySelector("#observablehq-poly_conv_sliders-05850d43"));
              if (name === "highlight_selected_cell") return new Inspector(document.querySelector("#observablehq-highlight_selected_cell-05850d43"));
              if (name === "reset_coeffs_button_display") return new Inspector(document.querySelector("#observablehq-reset_coeffs_button_display-05850d43"));
              if (name === "poly_input_slider_watch") return new Inspector(document.querySelector("#observablehq-poly_input_slider_watch-05850d43"));
              return ["svg","draw_bottom_line","draw_arrow","draw_original_img","draw_convolutional_kernel","draw_updated_img","draw_static_graph_orig","draw_static_graph_upd","draw_dyn_graph_orig","draw_dyn_graph_upd"].includes(name);
            });
          }, 200);
          </script>
        </div>
        <figure>
          <figcaption>
            <p>
              Hover over a pixel in the input grid (left, representing $x$)
              to highlight it and see the equivalent convolutional kernel
              for that pixel under the arrow.
              The result $x'$ of the convolution is shown on the right:
              note that different convolutional kernels are applied at different pixels,
              depending on their location.
            </p>
            <p>
              Click on the input grid to toggle pixel values between $0$ (white) and $1$ (blue).
              To randomize the input grid, press 'Randomize Grid'. To reset all pixels to $0$, press 'Reset Grid'.
              Use the sliders at the bottom to change the coefficients $w$.
              To reset all coefficients $w$ to $0$, press 'Reset Coefficients.'
            </p>
          </figcaption>
        </figure>

      <h3 id="chebnet">
        ChebNet
      </h3>
      <span>
        ChebNet <d-cite key="chebnet"></d-cite> refines this idea of polynomial filters by looking at polynomial filters of the form:
      </span>
        <d-math block>
          p_w(L) = \sum_{i = 1}^d w_i T_i(\tilde{L})
        </d-math>
      <span>
        where $T_i$ is the degree-$i$
        <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomial of the first kind</a> and
        $\tilde{L}$ is the normalized Laplacian defined using the largest eigenvalue of $L$:
        <d-footnote>
          We discuss the eigenvalues of the Laplacian $L$ in more detail in <a href="#spectral">a later section</a>.
        </d-footnote>
      </span>
        <d-math block>
          \tilde{L} = \frac{2L}{\lambda_{\max}(L)} - I_n.
        </d-math> 
      <p>
        What is the motivation behind these choices?
      </p>
        <ul>
          <li>
            $L$ is actually positive semi-definite: all of the eigenvalues of $L$ are not lesser than $0$.
            If $\lambda_{\max}(L) > 1$, the entries in the powers of $L$ rapidly increase in size.
            $\tilde{L}$ is effectively a scaled-down version of $L$, with eigenvalues guaranteed to be in the range $[-1, 1]$.
            This prevents the entries of powers of $\tilde{L}$ from blowing up.
            Indeed, in the <a href="#polynomial-convolutions">visualization above</a>: we restrict the higher-order coefficients
            when the unnormalized Laplacian $L$ is selected, but allow larger values when the normalized Laplacian $\tilde{L}$ is selected,
            in order to show the result $x'$ on the same color scale.
          </li>
          <li>
            The Chebyshev polynomials have certain interesting properties that make interpolation more numerically stable.
            We won't talk about this in more depth here,
            but will advise interested readers to take a look at <d-cite key="chebyshev"></d-cite> as a definitive resource.
          </li>
        </ul>
      
      <h3 id="poly-filters-equivariance">
        Polynomial Filters are Node-Order Equivariant
      </h3>
      <p>
        The polynomial filters we considered here are actually independent of the ordering of the nodes.
        This is particularly easy to see when the degree of the polynomial $p_w$ is $1$:
        where each node's feature is aggregated with the sum of its neighbour's features.
        Clearly, this sum does not depend on the order of the neighbours.
        A similar proof follows for higher degree polynomials:
        the entries in the powers of $L$ are equivariant to the ordering of the nodes.
      </p>
      <div class="math-details shaded-figure">
        <b>Details for the Interested Reader</b>
        <p>
          As above, let's assume an arbitrary node-order over the $n$ nodes of our graph.
          Any other node-order can be thought of as a permutation of this original node-order.
          We can represent any permutation by a
          <a href="https://en.wikipedia.org/wiki/Permutation_matrix">permutation matrix</a> $P$.
          $P$ will always be an orthogonal $0-1$ matrix:
          <d-math block>
            PP^T = P^TP = I_n.
          </d-math>
          Then, we call a function $f$ node-order equivariant iff for all permutations $P$:
          <d-math block>
            f(Px) = P f(x).
          </d-math>

          When switching to the new node-order using the permutation $P$,
          the quantities below transform in the following way:
          <d-math block>
            \begin{aligned}
              x &\to Px \\
              L &\to PLP^T \\
              L^i &\to PL^iP^T
            \end{aligned}
          </d-math>
          and so, for the case of polynomial filters where $f(x) = p_w(L) \ x$, we can see that:
          <d-math block>
            \begin{aligned}
              f(Px) & = \sum_{i = 0}^d w_i (PL^iP^T) (Px) \\
                    & = P \sum_{i = 0}^d w_i L^i x \\
                    & = P f(x).
            \end{aligned}
          </d-math> 
          as claimed.
        </p>
      </div>

      <h3>
        Embedding Computation
      </h3>
        <p>
          We now describe how we can build a graph neural network
          by stacking ChebNet (or any polynomial filter) layers
          one after the other with non-linearities,
          much like a standard CNN.
          In particular, if we have $K$ different polynomial filter layers,
          the $k^{\text{th}}$ of which has its own learnable weights $w^{(k)}$,
          we would perform the following computation:
        </p>
        <div id="observablehq-cheb_figure-fa1f970f" role="img" aria-label="Equations defining ChebNet."></div>
        <div id="observablehq-style-fa1f970f"></div>
        <!-- <p>Credit: <a href="https://observablehq.com/@ameyasd/updated-chebnet-equations">(Updated) ChebNet Equations by Ameya Daigavane</a></p> -->
        
        <script type="module">
        import {Runtime, Inspector} from "./observablehq-base/runtime.js";
        import define from "./notebooks/updated-chebnet-equations.js";
        setTimeout(() => {
          new Runtime().module(define, name => {
            if (name === "cheb_figure") return new Inspector(document.querySelector("#observablehq-cheb_figure-fa1f970f"));
            if (name === "style") return new Inspector(document.querySelector("#observablehq-style-fa1f970f"));
          });
        }, 200);
        </script>
        <p>
          Note that these networks
          reuse the same filter weights across different nodes,
          exactly mimicking weight-sharing in Convolutional Neural Networks (CNNs)
          which reuse weights for convolutional filters across a grid.
        </p>

    <h2 id="modern-gnns">
      Modern Graph Neural Networks
    </h2>
      <p>
        ChebNet was a breakthrough in learning localized filters over graphs,
        and it motivated many to think of graph convolutions from a different perspective.
      </p>
      <span>
        We return back to the result of convolving $x$ by the polynomial kernel $p_w(L) = L$,
        focussing on a particular vertex $v$:
      </span>
        <d-math block>
          \begin{aligned}
           (Lx)_v &= L_v x \\ 
                  &= \sum_{u \in G} L_{vu} x_u \\ 
                  &= \sum_{u \in G} (D_{vu} - A_{vu}) x_u \\ 
                  &= D_v \  x_v - \sum_{u \in \mathcal{N}(v)} x_u
          \end{aligned}
        </d-math>
      <p> 
        As we noted before, this is a $1$-hop localized convolution.
        But more importantly, we can think of this convolution as arising of two steps:
      </p>
        <ul>
          <li>Aggregating over immediate neighbour features $x_u$.</li>
          <li>Combining with the node's own feature $x_v$.</li>
        </ul>
      <p class="shaded-figure" style="padding-left: 1em;">
        <b>Key Idea:</b>
        What if we consider different kinds of 'aggregation' and 'combination' steps,
        beyond what are possible using polynomial filters?
      </p>
      <p>
        By ensuring that the aggregation is node-order equivariant,
        the overall convolution becomes node-order equivariant.
      </p>
      <p>
        These convolutions can be thought of as 'message-passing' between adjacent nodes:
        after each step, every node receives some 'information' from its neighbours.
      </p>
      <p>
        By iteratively repeating the $1$-hop localized convolutions $K$ times (i.e., repeatedly 'passing messages'),
        the receptive field of the convolution effectively includes all nodes upto $K$ hops away.
      </p>

      <h3>
        Embedding Computation
      </h3>
        <p>
          Message-passing forms the backbone of many GNN architectures today.
          We describe the most popular ones in depth below:
        </p>
          <ul>
            <li>Graph Convolutional Networks (GCN)<d-cite key="semi-supervised-gcn"></d-cite></li>
            <li>Graph Attention Networks (GAT)<d-cite key="gat"></d-cite></li>
            <li>Graph Sample and Aggregate (GraphSAGE)<d-cite key="graphsage"></d-cite></li>
            <li>Graph Isomorphism Network (GIN)<d-cite key="gin"></d-cite></li>
          </ul>
        
        <div class="shaded-figure l-screen" id="modern-gnns-equations" style="grid-column: page; padding-left: 2em; padding-right: 2em; padding-top: 0em;"
          role="img" aria-label="Equations defining the embedding computations for GCN, GAT, GraphSAGE and GIN models.">

          <div class="interactive-gnn-equations-fig_div" role="img"></div>
          <div class="interactive-gnn-equations-text_div"></div>
          <div class="interactive-gnn-equations-interactive_list" style="display: none;"></div>
          <div class="interactive-gnn-equations-style"></div>
    
          <script type="module">
          import {Runtime, Inspector} from "./observablehq-base/runtime.js";     
          import define from "./notebooks/interactive-gnn-equations.js";
          setTimeout(() => {
            new Runtime().module(define, name => {
              if (name === "fig_div") return Inspector.into(".interactive-gnn-equations-fig_div")();
              if (name === "text_div") return Inspector.into(".interactive-gnn-equations-text_div")();
              if (name === "interactive_list") return Inspector.into(".interactive-gnn-equations-interactive_list")();
              if (name === "style") return Inspector.into(".interactive-gnn-equations-style")();
            });
          }, 200);
          </script>
        </div>
  
    <h3>
     Thoughts
    </h3>
      <p>
        An interesting point is to assess different aggregation functions: are some better and others worse?
        <d-cite key="gin"></d-cite> demonstrates that aggregation functions indeed can be compared on how well
        they can uniquely preserve node neighbourhood features;
        we recommend the interested reader take a look at the detailed theoretical analysis there.
      </p>
      <p>
        Here, we've talk about GNNs where the computation only occurs at the nodes.
        More recent GNN models
        such as Message-Passing Neural Networks <d-cite key="neural-message-passing"></d-cite>
        and Graph Networks <d-cite key="graphnets"></d-cite>
        perform computation over the edges as well;
        they compute edge embeddings together with node embeddings.
        This is an even more general framework -
        but the same 'message passing' ideas from this section apply.
      </p>

    <h2 id="interactive">
      Interactive Graph Neural Networks
    </h2>
      <p>
        Below is an interactive visualization of these GNN models on small graphs.
        For clarity, the node features are just real numbers here, shown inside the squares next to each node,
        but the same equations hold when the node features are vectors.
      </p>

      <div class="shaded-figure l-screen" style="grid-column: page;" role="img"
        aria-label="An interactive visualization of different GNN models with update equations displayed at the selected node.">
        <div class="interactive-gnn-visualizations-viz_list" style="padding-left: 2em; padding-right: 2em"></div>
        <div class="interactive-gnn-visualizations-buttons"></div>
        <div class="interactive-gnn-visualizations-fig"></div>
        <div class="interactive-gnn-visualizations-eqn"></div>
        <div class="interactive-gnn-visualizations-network_display_hack" style="display: none;"></div>
        <div class="interactive-gnn-visualizations-style"></div>
      </div>

      <script type="module">
      import {Runtime, Inspector} from "./observablehq-base/runtime.js";
      import define from "./notebooks/interactive-gnn-visualizations.js";
      setTimeout(() => {
        new Runtime().module(define, name => {
          if (name === "viz_list") return Inspector.into(".interactive-gnn-visualizations-viz_list")();
          if (name === "buttons") return Inspector.into(".interactive-gnn-visualizations-buttons")();
          if (name === "fig") return Inspector.into(".interactive-gnn-visualizations-fig")();
          if (name === "eqn") return Inspector.into(".interactive-gnn-visualizations-eqn")();
          if (name === "network_display_hack") return Inspector.into(".interactive-gnn-visualizations-network_display_hack")();
          if (name === "style") return Inspector.into(".interactive-gnn-visualizations-style")();
          return ["interactive_list","select_fig","handle_click"].includes(name) || null;
        });
      }, 200);
      </script>
      <figure>
        <figcaption>
          Choose a GNN model using the tabs at the top. Click on a node to see the update equation at that node for the next iteration.
          Use the sliders on the left to change the weights for the current iteration, and watch how the update equation changes. 
        </figcaption>
      </figure>

      <p>
        In practice, each iteration above is generally thought of as a single 'neural network layer'.
        This ideology is followed by many popular Graph Neural Network libraries,
        <d-footnote>
        For example: <a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html">PyTorch Geometric</a>
        and <a href="https://stellargraph.readthedocs.io/en/stable/api.html#module-stellargraph.layer">StellarGraph</a>.
        </d-footnote>
        allowing one to compose different types of graph convolutions in the same model.
      </p>

    <h2 id="from-local-to-global">
      From Local to Global Convolutions       
    </h2>
      <p>
        The methods we've seen so far perform 'local' convolutions:
        every node's feature is updated using a function of its local neighbours' features.
      </p>
      <p>
        While performing enough steps of message-passing will eventually ensure that
        information from all nodes in the graph is passed,
        one may wonder if there are more direct ways to perform 'global' convolutions.
      </p>
      <p>
        The answer is yes; we will now describe an approach that was actually first put forward
        in the context of neural networks by <d-cite key="spectral-networks"></d-cite>,
        much before any of the GNN models we looked at above.
      </p> 

      <h3 id="spectral">
        Spectral Convolutions      
      </h3>
      <p>
        As before, we will focus on the case where nodes have one-dimensional features.
        After choosing an arbitrary node-order, we can stack all of the node features to get a
        'feature vector' $x \in \mathbb{R}^n$.
      </p>
      <p class="shaded-figure" style="padding-left: 1em;">
        <b>Key Idea:</b>
        Given a feature vector $x$, 
        the Laplacian $L$ allows us to quantify how smooth $x$ is, with respect to $G$.
      </p>
      <p>
        How?
      </p>
      <p>
        After normalizing $x$ such that $\sum_{i = 1}^n x_i^2 = 1$,
        if we look at the following quantity involving $L$:
        <d-footnote>
          <d-math>R_L</d-math> is formally called the <a href="https://en.wikipedia.org/wiki/Rayleigh_quotient">Rayleigh quotient</a>.
        </d-footnote> 
        <d-math block>
          R_L(x) = \frac{x^T L x}{x^T x} = \frac{\sum_{(i, j) \in E} (x_i - x_j)^2}{\sum_i x_i^2} = \sum_{(i, j) \in E} (x_i - x_j)^2.
        </d-math>
        we immediately see that feature vectors $x$ that assign similar values to 
        adjacent nodes in $G$ (hence, are smooth) would have smaller values of $R_L(x)$.
      </p>
      <p>
        $L$ is a real, symmetric matrix, which means it has all real eigenvalues $\lambda_1 \leq \ldots \leq \lambda_{n}$.
        <d-footnote>
          An eigenvalue $\lambda$ of a matrix $A$ is a value
          satisfying the equation $Au = \lambda u$ for a certain vector $u$, called an eigenvector.
          For a friendly introduction to eigenvectors,
          please see <a href="http://www.sosmath.com/matrix/eigen0/eigen0.html">this tutorial</a>.
        </d-footnote>
        Further, the corresponding eigenvectors $u_1, \ldots, u_{n}$ can be taken to be orthonormal:
        <d-math block style="text-align: center;">
          u_{k_1}^T u_{k_2} =
          \begin{cases}
            1 \quad \text{ if } {k_1} = {k_2}. \\
            0 \quad \text{ if } {k_1} \neq {k_2}.
          \end{cases}
        </d-math>
        It turns out that these eigenvectors of $L$ are successively less smooth, as $R_L$ indicates:
        <d-footnote>This is the <a href="https://en.wikipedia.org/wiki/Min-max_theorem">min-max theorem for eigenvalues.</a></d-footnote>
        <d-math block>
          \underset{x, \ x \perp \{u_1, \ldots, u_{i - 1}\}}{\text{argmin}} R_L(x) = u_i.
          \qquad
          \qquad
          \qquad
          \min_{x, \ x \perp \{u_1, \ldots, u_{i - 1}\}} R_L(x) = \lambda_i.
        </d-math>
        The set of eigenvalues of $L$ are called its 'spectrum', hence the name!
        We denote the 'spectral' decomposition of $L$ as:
        <d-math block>
          L = U \Lambda U^T.
        </d-math>
        where $\Lambda$ is the diagonal matrix of sorted eigenvalues,
        and $U$ denotes the matrix of the eigenvectors (sorted corresponding to increasing eigenvalues):
        <d-math block>
          \Lambda = \begin{bmatrix}
                        \lambda_{1} &        & \\
                                    & \ddots & \\
                                    &        & \lambda_{n}
                    \end{bmatrix}
          \qquad
          \qquad
          \qquad
          \qquad
          U = \begin{bmatrix}  \\ u_1 \ \cdots \ u_n \\ \end{bmatrix}.
        </d-math>
        The orthonormality condition between eigenvectors gives us that $U^T U = I$, the identity matrix.
        As these $n$ eigenvectors form a basis for $\mathbb{R}^n$,
        any feature vector $x$ can be represented as a linear combination of these eigenvectors:
        <d-math block>
          x = \sum_{i = 1}^n \hat{x_i} u_i = U \hat{x}.
        </d-math>
        where $\hat{x}$ is the vector of coefficients $[x_0, \ldots x_n]$.
        We call $\hat{x}$ as the spectral representation of the feature vector $x$.
        The orthonormality condition allows us to state:
        <d-math block>
          x = U \hat{x} \quad \Longleftrightarrow \quad U^T x = \hat{x}.
        </d-math>
        This pair of equations allows us to interconvert
        between the 'natural' representation $x$ and the 'spectral' representation $\hat{x}$
        for any vector $x \in \mathbb{R}^n$.
      </p>
      <h3 id="spectral-decompositions-of-natural-images">
        Spectral Representations of Natural Images
      </h3>
      <p>
        As discussed before, we can consider any image as a grid graph, where each pixel is a node,
        connected by edges to adjacent pixels.
        Thus, a pixel can have either $3, 5,$ or $8$ neighbours, depending on its location within the image grid.
        Each pixel gets a value as part of the image. If the image is grayscale, each value will be a single 
        real number indicating how dark the pixel is. If the image is colored, each value will be a $3$-dimensional
        vector, indicating the values for the red, green and blue (RGB) channels.
        <d-footnote>We use the alpha channel as well in the visualization below, so this is actually RGBA.</d-footnote>
      </p>
      <p>
        This construction allows us to compute the graph Laplacian and the eigenvector matrix $U$.
        Given an image, we can then investigate what its spectral representation looks like.
      </p>
      <p>
        To shed some light on what the spectral representation actually encodes,
        we perform the following experiment over each channel of the image independently:  
      </p>
        <ul>
          <li>
            We first collect all pixel values across a channel into a feature vector $x$.
          </li>
          <li>
            Then, we obtain its spectral representation $\hat{x}$.
            <d-math block>
              \hat{x} = U^T x
            </d-math>
          </li>
          <li>
            We truncate this to the first $m$ components to get $\hat{x}_m$.
            By truncation, we mean zeroing out all of the remaining $n - m$ components of $\hat{x}$.
            This truncation is equivalent to using only the first $m$ eigenvectors to compute the spectral representation.
            <d-math block>
              \hat{x}_m = \text{Truncate}_m(\hat{x})
            </d-math>
          </li>
          <li>
            Then, we convert this truncated representation $\hat{x}_m$ back to the natural basis to get $x_m$.
            <d-math block>
              x_m = U \hat{x}_m
            </d-math>
          </li>
        </ul>
      <p>
        Finally, we stack the resulting channels back together to get back an image.
        We can now see how the resulting image changes with choices of $m$.
        Note that when $m = n$, the resulting image is identical to the original image,
        as we can reconstruct each channel exactly.
      </p>
      <div class="shaded-figure l-screen" id="spectral-decompositions-viz" style="grid-column: page; padding-bottom: 1em; padding-top: 1em;">
        <div id="observablehq-spectralDecompositionsAll-59114e0b"></div>
        <div id="observablehq-updateArrowCaption-59114e0b" style="display: none;"></div>
        <div id="observablehq-drawArrow-59114e0b" style="display: none;"></div>
        <div id="observablehq-drawCurrBaseImg-59114e0b" style="display: none;"></div>
        <div id="observablehq-drawCurrUpdImg-59114e0b" style="display: none;"></div>
        <div id="observablehq-style-59114e0b" style="display: none;"></div>
        <!-- <p>Credit: <a href="https://observablehq.com/@ameyasd/spectral-decompositions-of-natural-images">Spectral Decompositions of Natural Images by Ameya Daigavane</a></p> -->

        <script type="module">
        import {Runtime, Inspector} from "./observablehq-base/runtime.js";   
        import define from "./notebooks/spectral-decompositions-of-natural-images.js";
        setTimeout(() => {
          new Runtime().module(define, name => {
            if (name === "spectralDecompositionsAll") return new Inspector(document.querySelector("#observablehq-spectralDecompositionsAll-59114e0b"));
            if (name === "updateArrowCaption") return new Inspector(document.querySelector("#observablehq-updateArrowCaption-59114e0b"));
            if (name === "drawArrow") return new Inspector(document.querySelector("#observablehq-drawArrow-59114e0b"));
            if (name === "drawCurrBaseImg") return new Inspector(document.querySelector("#observablehq-drawCurrBaseImg-59114e0b"));
            if (name === "drawCurrUpdImg") return new Inspector(document.querySelector("#observablehq-drawCurrUpdImg-59114e0b"));
            if (name === "style") return new Inspector(document.querySelector("#observablehq-style-59114e0b"));
          });
        }, 200);
        </script>
      </div>
      <figure>
        <figcaption>
          Use the radio buttons at the top to chose one of the four sample images.
          Each of these images has been taken from the ImageNet <d-cite key="imagenet"></d-cite>
          dataset and downsampled to $50$ pixels wide and $40$ pixels tall.
          As there are $n = 50 \times 40 = 2000$ pixels in each image, there are $2000$ Laplacian eigenvectors.
          Use the slider at the bottom to change the number of spectral components to keep, noting how
          images get progressively blurrier as the number of components decrease.
        </figcaption>
      </figure>
      <p>
        As $m$ decreases, we see that the output image $x_m$ gets blurrier.
        If we decrease $m$ to $1$, the output image $x_m$ is entirely the same color throughout.
        We see that we do not need to keep all $n$ components;
        we can retain a lot of the information in the image with significantly fewer components.

        We can relate this to the Fourier decomposition of images:
        the more eigenvectors we use, the higher frequencies we can represent on the grid.
      </p>
      <p>
        To complement the visualization above,
        we additionally visualize the first few eigenvectors on a smaller $8 \times 8$ grid below.
        We change the coefficients of the first $10$ out of $64$ eigenvectors
        in the spectral representation
        and see how the resulting image changes:
      </p>
      <div class="shaded-figure l-screen" id="spectral-conversions" style="grid-column: page; padding-bottom: 0; padding-top: 0;">
        <div id="observablehq-figcaptions-6ac8e785"></div>
        <div id="observablehq-spec_conv_main_div-6ac8e785" class="l-page" style="padding-left: 80px;"></div>
        <div id="observablehq-spec_color_scale-6ac8e785" style="position: relative; left: 116px; top: -182px;"></div>
        <div id="observablehq-spec_conv_sliders-6ac8e785" class="l-page"></div>
        <div id="observablehq-subgrid_main_div-6ac8e785"></div>
        <div id="observablehq-spec_conv_buttons_display-6ac8e785" style="margin-top: 2em; margin-bottom: 1em;"></div>
        <div id="observablehq-spec_input_slider_watch-6ac8e785" style="display: none;"></div>
        <!-- <p>Credit: <a href="https://observablehq.com/@ameyasd/interactive-spectral-conversions">Interactive Spectral Conversions by Ameya Daigavane</a></p> -->

      </div>
      <script type="module">
        import {Runtime, Inspector} from "./observablehq-base/runtime.js"; 
        import define from "./notebooks/interactive-spectral-conversions.js";
        setTimeout(() => {
          new Runtime().module(define, name => {
            if (name === "figcaptions") return new Inspector(document.querySelector("#observablehq-figcaptions-6ac8e785"));
            if (name === "spec_conv_main_div") return new Inspector(document.querySelector("#observablehq-spec_conv_main_div-6ac8e785"));
            if (name === "spec_color_scale") return new Inspector(document.querySelector("#observablehq-spec_color_scale-6ac8e785"));
            if (name === "subgrid_main_div") return new Inspector(document.querySelector("#observablehq-subgrid_main_div-6ac8e785"));
            if (name === "spec_conv_sliders") return new Inspector(document.querySelector("#observablehq-spec_conv_sliders-6ac8e785"));
            if (name === "spec_conv_buttons_display") return new Inspector(document.querySelector("#observablehq-spec_conv_buttons_display-6ac8e785"));
            if (name === "spec_input_slider_watch") return new Inspector(document.querySelector("#observablehq-spec_input_slider_watch-6ac8e785"));
            return ["svg","draw_img","draw_static_graph","draw_dyn_graph","draw_eigenvectors"].includes(name);
          });
        }, 200);
      </script>
      <figure>
        <figcaption>
          Move the sliders to change the spectral representation $\hat{x}$ (right),
          and see how $x$ itself changes on the image (left).
          Note how the first eigenvectors are much 'smoother' than the later ones,
          and the many patterns we can make with only $10$ eigenvectors.
        </figcaption>
      </figure>

      <p>
        These visualizations should convince you that the first eigenvectors are indeed smooth,
        and the smoothness correspondingly decreases as we consider later eigenvectors.
      </p>
      <p>
        For any image $x$, we can think of
        the initial entries of the spectral representation $\hat{x}$
        as capturing 'global' image-wide trends, which are the low-frequency components,
        while the later entries as capturing 'local' details, which are the high-frequency components.
      </p>

      <h3>Embedding Computation</h3>
      <p>
        We now have the background to understand spectral convolutions
        and how they can be used to compute embeddings/feature representations of nodes.
      </p>
      <p>
        As before, the model we describe below has $K$ layers:
        each layer $k$ has learnable parameters $\hat{w}^{(k)}$,
        called the 'filter weights'.
        These weights will be convolved with the spectral representations of the node features.
        As a result, the number of weights needed in each layer is equal to $m$, the number of 
        eigenvectors used to compute the spectral representations.
        We had shown in the previous section that we can take $m \ll n$
        and still not lose out on significant amounts of information.
      </p>
      <p>
        Thus, convolution in the spectral domain enables the use of significantly fewer parameters
        than just direct convolution in the natural domain.
        Further, by virtue of the smoothness of the Laplacian eigenvectors across the graph,
        using spectral representations automatically enforces an inductive bias for
        neighbouring nodes to get similar representations.
      </p>
      <p>
        Assuming one-dimensional node features for now,
        the output of each layer is a vector of node representations $h^{(k)}$,
        where each node's representation corresponds to a row
        of the vector.
      </p>
      <div class="spec_figure_init" role="img" aria-label="Equations defining spectral convolutions."></div>
      <p>
        We fix an ordering of the nodes in $G$. This gives us the adjacency matrix $A$ and the graph Laplacian $L$,
        allowing us to compute $U_m$.
        Finally, we can describe the computation that the layers perform, one after the other:
      </p>
      <div class="spec_figure"></div>
      <div class="spec_figure_style"></div>

      <script type="module">
      import {Runtime, Inspector} from "./observablehq-base/runtime.js";    
      import define from "./notebooks/spectral-convolutions-equation.js";
      setTimeout(() => {
        new Runtime().module(define, name => {
          if (name === "spec_figure_init") return Inspector.into(".spec_figure_init")();
          if (name === "spec_figure") return Inspector.into(".spec_figure")();
          if (name === "style") return Inspector.into(".spec_figure_style")();
        });
      }, 200);
      </script>
      <p>
        The method above generalizes easily to the case where each $h^{(k)} \in \mathbb{R}^{d_k}$, as well:
        see <d-cite key="spectral-networks"></d-cite> for details.
      </p>
      <p>
        With the insights from the previous section, we see that convolution in the spectral-domain of graphs
        can be thought of as the generalization of convolution in the frequency-domain of images.
      </p>

      <h3 id="spectral-equivariance">
        Spectral Convolutions are Node-Order Equivariant
      </h3>
      <p>
        We can show spectral convolutions are node-order equivariant using a similar approach
        as for Laplacian polynomial filters. 
      </p>
      <div class="math-details shaded-figure">
        <b>
          Details for the Interested Reader
        </b>
        <p>
          As in <a href="#poly-filters-equivariance">our proof before</a>,
          let's fix an arbitrary node-order.
          Then, any other node-order can be represented by a
          permutation of this original node-order.
          We can associate this permutation with its permutation matrix $P$.

          Under this new node-order,
          the quantities below transform in the following way:
          <d-math block>
            \begin{aligned}
              x &\to Px \\
              A &\to PAP^T \\
              L &\to PLP^T \\
              U_m &\to PU_m
            \end{aligned}
          </d-math>
          which implies that, in the embedding computation:
          <d-math block>
            \begin{aligned}
              \hat{x} &\to \left(PU_m\right)^T (Px) = U_m^T x = \hat{x} \\
              \hat{w} &\to \left(PU_m\right)^T (Pw) = U_m^T w = \hat{w} \\
              \hat{g} &\to \hat{g} \\
              g &\to (PU_m)\hat{g} = P(U_m\hat{g}) = Pg
            \end{aligned}
          </d-math>
          Hence, as $\sigma$ is applied elementwise:
          <d-math block>
            f(Px) = \sigma(Pg) = P \sigma(g) = P f(x)
          </d-math>
          as required.
          Further, we see that the spectral quantities $\hat{x}, \hat{w}$ and $\hat{g}$
          are unchanged by permutations of the nodes.
          <d-footnote>
          Formally, they are what we would call node-order invariant.
          </d-footnote>
        </p>
      </div>

      <p>
        The theory of spectral convolutions is mathematically well-grounded;
        however, there are some key disadvantages that we must talk about:
      </p>
      <ul>
        <li>
          We need to compute the eigenvector matrix $U_m$ from $L$. For large graphs, this becomes quite infeasible.
        </li>
        <li>
          Even if we can compute $U_m$, global convolutions themselves are inefficient to compute,
          because of the repeated
          multiplications with $U_m$ and $U_m^T$.
        </li>
        <li>
          The learned filters are specific to the input graphs,
          as they are represented in terms
          of the spectral decomposition of input graph Laplacian $L$.
          This means they do not transfer well to new graphs
          which have significantly different structure (and hence, significantly
          different eigenvalues) <d-cite key="spectral-transfer"></d-cite>.
        </li>
      </ul>

      <p>
        While spectral convolutions have largely been superseded by
        'local' convolutions for the reasons discussed above,
        there is still much merit to understanding the ideas behind them.
        Indeed, a recently proposed GNN model called Directional Graph Networks
        <d-cite key="directional-gnns"></d-cite>
        actually uses the Laplacian eigenvectors
        and their mathematical properties
        extensively.
      </p>

      <h3 id="graph-embeddings">
        Global Propagation via Graph Embeddings
      </h3>
      <p>
        A simpler way to incorporate graph-level information
        is to compute embeddings of the entire graph by pooling node
        (and possibly edge) embeddings,
        and then using the graph embedding to update node embeddings,
        following an iterative scheme similar to what we have looked at here.
        This is an approach used by Graph Networks
        <d-cite key="graphnets"></d-cite>.
        We will briefly discuss how graph-level embeddings
        can be constructed in <a href="#pooling">Pooling</a>.
        However, such approaches tend to ignore the underlying
        topology of the graph that spectral convolutions can capture.
      </p>

    <h2 id="learning">
      Learning GNN Parameters
    </h2>
      <p>
        All of the embedding computations we've described here, whether spectral or spatial, are completely differentiable.
        This allows GNNs to be trained in an end-to-end fashion, just like a standard neural network,
        once a suitable loss function $\mathcal{L}$ is defined:
      </p>
        <ul>
          <li>
            <b>Node Classification</b>: By minimizing any of the standard losses for classification tasks,
            such as categorical cross-entropy when multiple classes are present:
            <d-math block>
              \mathcal{L}(y_v, \hat{y_v}) = -\sum_{c} y_{vc} \log{\hat{y_{vc}}}.
            </d-math>
            where $\hat{y_{vc}}$ is the predicted probability that node $v$ is in class $c$.
            GNNs adapt well to the semi-supervised setting, which is when only some nodes in the graph are labelled.
            In this setting, one way to define a loss $\mathcal{L}_{G}$ over an input graph $G$ is:
            <d-math block>
              \mathcal{L}_{G} = \frac{\sum\limits_{v \in \text{Lab}(G)} \mathcal{L}(y_v, \hat{y_v})}{| \text{Lab}(G) |}
            </d-math>
            where, we only compute losses over labelled nodes <d-math>\text{Lab}(G)</d-math>.
          </li>
          <li>
            <b>Graph Classification</b>: By aggregating node representations,
            one can construct a vector representation of the entire graph.
            This graph representation can be used for any graph-level task, even beyond classification.
            See <a href="#pooling">Pooling</a> for how representations of graphs can be constructed.
          </li>
          <li>
            <b>Link Prediction</b>: By sampling pairs of adjacent and non-adjacent nodes,
            and use these vector pairs as inputs to predict the presence/absence of an edge.
            For a concrete example, by minimizing the following 'logistic regression'-like loss:
            <d-math block>
              \begin{aligned}
              \mathcal{L}(y_v, y_u, e_{vu}) &= -e_{vu} \log(p_{vu}) - (1 - e_{vu}) \log(1 - p_{vu}) \\
              p_{vu} &= \sigma(y_v^Ty_u)
              \end{aligned}
            </d-math>
            where $\sigma$ is the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a>,
            and $e_{vu} = 1$ iff there is an edge between nodes $v$ and $u$, being $0$ otherwise.
          </li>
          <li>
            <b>Node Clustering</b>: By simply clustering the learned node representations.
          </li>
        </ul>

      <p>
        The broad success of pre-training for natural language processing models
        such as ELMo <d-cite key="elmo"></d-cite> and BERT <d-cite key="bert"></d-cite>
        has sparked interest in similar techniques for GNNs
        <d-cite key="strategies-pre-training,m3s,when-does-self-help,self-supervised-graphs-insights"></d-cite>.
        The key idea in each of these papers is to train GNNs to predict
        local (eg. node degrees, clustering coefficient, masked node attributes)
        and/or global graph properties (eg. pairwise distances, masked global attributes).
      </p>
      <p>
        Another self-supervised technique is to enforce that neighbouring nodes get similar embeddings,
        mimicking random-walk approaches such as node2vec <d-cite key="node2vec"></d-cite> and DeepWalk <d-cite key="deepwalk"></d-cite>:
      </p>
        <d-math block>
          L_{G} = \sum_{v} \sum_{u \in N_R(v)} \log\frac{\exp{z_v^T z_u}}{\sum\limits_{u'} \exp{z_{u'}^T z_u}}.
        </d-math>
      <p>
        where $N_R(v)$ is a multi-set of nodes visited when random walks are started from $v$.
        For large graphs, where computing the sum over all nodes may be computationally expensive,
        techniques such as Noise Contrastive Estimation <d-cite key="nce,nce-embeddings"></d-cite> are especially useful.
      </p>

    <!--
    <h2 id="gnns-vs-cnns">
      Are GNNs 'better' than CNNs?
    </h2>
      <p>
        We've shown how GNNs arose as a generalization of CNNs to arbitrary graphs.
        Given some of the powerful constructions we've explored in this article,
        a valid question to ask is if GNNs represent a more powerful class of models than CNNs.
  
        To enable a comparison, we now consider a problem defined on a fixed-size grid,
        allowing both CNNs and GNNs to be used.
      </p>
    
      <h3 id="game-of-life-problem">
        The Game of Life
      </h3>
      <p>
        Conway's Game of Life <d-cite key="game-of-life"></d-cite> is a simple game played on an infinite grid of cells. (Here, we focus on finite $8 \times 8$ grids.)
        Initially, each cell is either alive or dead.
        At the next step, the grid configuration updates in the following manner:
      </p>
        <ul>
          <li>Alive cells which have fewer than 2 alive neighbours, die by loneliness.</li>
          <li>Alive cells which have greater than 3 alive neighbours, die by overpopulation.</li>
          <li>Dead cells which have exactly 3 alive neighbours, become alive.</li>
          <li>Every other cell maintains its state.</li>
        </ul>
        <figure id="game-of-life-example" class="l-page" style="text-align: center;">
        <img src="images/game-of-life-example.svg" style="width: 80%;"
             alt="A Game of Life grid with an initial configuration, updated to a new configuration. Alive cells are filled in with black. Dead cells are filled in with white.">
        <figcaption>
          A grid with an initial configuration, updated to a new configuration.
          Alive cells are filled in with black. Dead cells are filled in with white.
        </figcaption>
      </figure>
      <p>
        The Game of Life is simple, but research <d-cite key='game-of-life-nns'></d-cite> has shown that neural networks struggle to solve the Game of Life Problem!
      </p>
      <p class="shaded-figure" style="padding-left: 1em;">
        <b>The Game of Life Problem:</b>
        Given a grid with an initial configuration of alive and dead cells, compute the next configuration of the grid, according to the rules of the Game of Life.
      </p>
      <p>
        The Game of Life rules do not vary across the grid:
        this allows both CNNs and GNNs to model the dynamics of the Game of Life, since they share weights across pixels/nodes.
      </p>
      <p>
        In this spirit, <d-cite key='game-of-life-nns'></d-cite> defines a minimal 3-layer CNN model that can solve the Game of Life Problem perfectly.
        However, they find that only CNN models with many more parameters can actually find the optimal solution consistently, when trained with stochastic gradient descent.
      </p>
      <p>
        How would GNNs fare at the Game of Life?
        We mimic <d-cite key='game-of-life-nns'></d-cite>, and create an equivalent minimal 3-layer GCN model
        <d-footnote>
          See <a href="#minimal-models">Appendix: Minimal Models for The Game of Life</a>.
        </d-footnote>
        that can solve the Game of Life Problem perfectly.
      </p>
      <p>
        Note that the rules of the Game of Life treat all neighbours of a cell on an equal footing:
        all that matters is the count of alive neighbours surrounding a cell, not their positions.
        This aligns well with the inductive bias of the GCN models to treat each neighbour equally.
        <d-footnote>
          Indeed, on a grid, the GCN variant here is equivalent to a uniform $3 \times 3$ filter (except for the center pixel which can have a different weight).
        </d-footnote>
        For this reason, we would expect GCN models to perform better than CNN models on this task,
        which would have to learn to weigh neighbours equally.
      </p>
      <p>
        Following <d-cite key='game-of-life-nns'></d-cite>, we vary the number of parameters in each of these models,
        relative to the minimal model for each class. This variation is captured by the overparametrization factor ($m$):
        <d-footnote>
          $m = 1$ recovers the structure of the minimal model. As a function of the overparametrization factor $m$,
          the GCN models have $2m^2 + 9m + 2$ parameters, while the CNN models have $2m^2 + 23m + 2$.
          Thus, the CNN models vary from about $2\times$ (at $m = 1$) to about $1.5\times$ (at $m = 10$) as big as the GCN models,
          in terms of number of parameters.
        </d-footnote>
        <d-footnote>
          The linear layer in the CNNs is implemented as a standard 2D-convolution with filter shape $1 \times 1$.
        </d-footnote>
      </p>
      <figure id="overparametrization-factor" class="l-page" style="text-align: center;">
        <img src="images/overparametrization-factor.svg" style="width: 80%;"
             alt="Architectures for the CNN and GCN models. The CNN has a 3x3 Conv2D + ReLU + Linear + ReLU + Linear structure, while the GCN has a GCNConv + ReLU + Linear + ReLU + Linear structure. Both models output a 2-dimensional vector at each cell indicating their predictions.">
      </figure>
      <p>
        However, our experiments show that CNNs and GCNs perform very similarly on the Game of Life.
        For each value of the overparametrization factor, both models are trained separately until the validation loss doesn't decrease for 300 iterations.
        <d-footnote>
          See <a href="#game-of-life-details">Appendix: The Game of Life Experiment Details</a>.
        </d-footnote>
        The results below are for 40 different random initializations for each model.
      </p>
      <figure id="validation-accuracy-boxplot" class="l-screen" style="margin-top: 0; text-align: center;">
        <img src="images/validation-accuracy-boxplot.svg" style="width: 80%;"
             alt="Distribution of validation accuracies for each trained model as the overparametrization factor is varied. Both GCNs and CNNs do similarly, with increasing performance as the number of parameters increase.">
        <figcaption style="width: 50%; margin-left: 25%; margin-right: 25%;">
          Distribution of validation accuracies for each trained model as the overparametrization factor ($m$) is varied.
          The boxplot bodies extend from the 25th percentile to the 75th percentile accuracies, while the whiskers extend from the 5th percentile to the 95th percentile accuracies.
          The horizontal lines in the middle of the boxplot bodies indicate the median accuracy.
        </figcaption>
      </figure>
      <p>
        Defining a successful model as one that has perfect validation accuracy,
        we find that GCNs and CNNs have similar probabilities of success to learn the Game of Life, increasing with the number
        of parameters in the models.
      </p>
      <figure id="success-probabilities" class="l-page" style="margin-top: 0; text-align: center;">
        <img src="images/success-probabilities.svg" style="width: 100%;"
             alt="Fraction of models that could correctly learn the rules of the Game of Life. Both GCNs and CNNs perform similarly.">
      </figure>
      <p>
        These experiments suggest that the GCN models don't learn the rules of the Game of Life in the form they are given above,
        minimizing the benefits of their inductive bias.
      </p>
      <p>
        To understand what these models have learned, we have created the interactive visualization below!
        See predictions for the worst and best performing models in each class, at overparametrization factors 1, 2, 5 and 10.
      </p>
      <div class="shaded-figure l-screen" style="margin-bottom: 1em; grid-column: page;">
        <div class="game_of_life_buttons_div"></div>
        <div class="inputs"></div>
        <div class="game_of_life_main_div"></div>
        <div class="style"></div>
      </div>
        
      <script type="module">
        import {Runtime, Inspector} from "https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js";
        import define from "https://api.observablehq.com/d/5cda95a13cb635cf.js?v=3";
        (new Runtime).module(define, name => {
          if (name === "game_of_life_buttons_div") return Inspector.into(".game_of_life_buttons_div")();
          if (name === "inputs") return Inspector.into(".inputs")();
          if (name === "game_of_life_main_div") return Inspector.into(".game_of_life_main_div")();
          if (name === "style") return Inspector.into(".style")();
          return ["svg","draw_text","draw_separator_lines","draw_inp_img","draw_pred_img_gcn","draw_pred_img_cnn","draw_next_img"].includes(name) || null;
        });
      </script>
      <figure>
        <figcaption style="margin-bottom: 1em;">
          Modify the input grid (left) by clicking on the individual cells to toggle them (black: alive, white: dead), or randomize the entire grid with the 'Randomize Grid' button.
          Clicking the 'Reset' button sets all cells as dead.
        </figcaption>
      </figure>
      <p>
        The visualization above serves as an excellent test for generalizability of these models, beyond the standard validation set metrics.
        On closer observation, we see that:
      </p>
        <ul>
          <li>The best CNN and GCN models at $m = 1$ have nearly identical predictions.</li>
          <li>Although not identical, there are many similarities between the predictions of the worst CNN and GCN models at $m = 5$.</li>
        </ul> -->

    <h2 id="further-reading">
      Conclusion and Further Reading
    </h2>
      
      <p>
        While we have looked at many techniques and ideas in this article,
        the field of Graph Neural Networks is extremely vast.
        We have been forced to restrict our discussion to a small subset of the entire literature,
        while still communicating the key ideas and design principles behind GNNs.
        We recommend the interested reader take a look at
        <d-cite key="gnn-survey,gnn-review"></d-cite> for a more comprehensive survey.
      </p>
      <p>
        We end with pointers and references for additional concepts readers might be interested in:
      </p>

      <h3 id="practical-techniques">
        GNNs in Practice
      </h3>
      <p>
        It turns out that accomodating the different structures of graphs is often hard to do efficiently,
        but we can still represent many GNN update equations using
        as sparse matrix-vector products (since generally, the adjacency matrix is sparse for most real-world graph datasets.)
        For example, the GCN variant discussed here can be represented as:
        <d-math block>
          h^{(k)} = D^{-1} A \cdot h^{(k - 1)} {W^{(k)}}^T + h^{(k - 1)} {B^{(k)}}^T.
        </d-math>
        Restructuring the update equations in this way allows for efficient vectorized implementations of GNNs on accelerators
        such as GPUs.
      </p>
      <p>
        Regularization techniques for standard neural networks,
        such as Dropout <d-cite key="dropout"></d-cite>,
        can be applied in a straightforward manner to the parameters
        (for example, zero out entire rows of $W^{(k)}$ above).
        However, there are graph-specific techniques such as DropEdge <d-cite key="dropedge"></d-cite>
        that removes entire edges at random from the graph,
        that also boost the performance of many GNN models.
      </p>

      <h3 id="different-kinds-of-graphs">
        Different Kinds of Graphs
      </h3>
      <p>
        Here, we have focused on undirected graphs, to avoid going into too many unnecessary details.
        However, there are some simple variants of spatial convolutions for:
      </p>
        <ul>
          <li>Directed graphs: Aggregate across in-neighbourhood and/or out-neighbourhood features. </li>
          <li>Temporal graphs: Aggregate across previous and/or future node features.</li>
          <li>Heterogeneous graphs: Learn different aggregation functions for each node/edge type.</li>
        </ul>
      <p>
        There do exist more sophisticated techniques that can take advantage of the different structures of these graphs:
        see <d-cite key="gnn-survey,gnn-review"></d-cite> for more discussion.
      </p>

      <h3 id="pooling">
        Pooling
      </h3>
        <p>
          This article discusses how GNNs compute useful representations of nodes.
          But what if we wanted to compute representations of graphs for graph-level tasks (for example, predicting the toxicity of a molecule)?
        </p>
        <p>
          A simple solution is to just aggregate the final node embeddings and pass them through another neural network $\text{PREDICT}_G$:
          <d-math block>
            h_G = \text{PREDICT}_G \Big( \text{AGG}_{v \in G}\left(\{ h_v \} \right) \Big)
          </d-math>
          However, there do exist more powerful techniques for 'pooling' together node representations:
        </p>
          <ul>
            <li>SortPool<d-cite key="sortpool"></d-cite>: Sort vertices of the graph to get a fixed-size node-order invariant representation of the graph, and then apply any standard neural network architecture.</li>
            <li>DiffPool<d-cite key="diffpool"></d-cite>: Learn to cluster vertices, build a coarser graph over clusters instead of nodes, then apply a GNN over the coarser graph. Repeat until only one cluster is left. </li>
            <li>SAGPool<d-cite key="sagpool"></d-cite>: Apply a GNN to learn node scores, then keep only the nodes with the top scores, throwing away the rest. Repeat until only one node is left.</li>
          </ul>
      
    <h2 id="supplementary">
      Supplementary Material
    </h2>
      <h3 id="experiments-notebooks">
        Reproducing Experiments
      </h3>
      <p>
        The experiments from
        <a href="#spectral-decompositions-of-natural-images">Spectral Representations of Natural Images</a>
        can be reproduced using the following
        Colab <img src="images/colab.svg" alt="Google Colaboratory" style="position: relative; top: 2px"> notebook:
        <a href="https://colab.research.google.com/github/google-research/google-research/blob/master/understanding_convolutions_on_graphs/SpectralRepresentations.ipynb">Spectral Representations of Natural Images</a>.
      </p>
<!-- 
      <p>
        The experiments from <a href="#gnns-vs-cnns">Are GNNs 'better' than CNNs?</a> can be reproduced using the following Colab <img src="images/colab.svg" alt="Google Colaboratory" style="position: relative; top: 2px"> notebook:
      </p>
        <ul>
          <li><a href="https://colab.research.google.com/github/google-research/google-research/blob/master/understanding_convolutions_on_graphs/TheGameOfLifeWithGNNs.ipynb">The Game of Life Colab</a></li>
        </ul>
      <p>
        The saved models (in TensorFlow Saved Model format) can be found at the Google Drive <img src="images/google-drive.svg" alt="Google Drive" width="20" height="20" style="position: relative; top: 2px"> folders below.
        <d-footnote>Currently unavailable, pending official data release.</d-footnote>
        These saved models were converted to a TensorFlow.js Graphs Model using the <a href="https://github.com/tensorflow/tfjs/tree/master/tfjs-converter">TensorFlow.js converter script</a>.
      </p>
        <ul>
          <li><a href="">The Game of Life Saved Models </a></li>
          <li><a href="">The Game of Life Saved Models Converted</a></li>
        </ul>
 -->
      <h3 id="visualizations-notebooks">
        Recreating Visualizations
      </h3>
      <p>
        To aid in the creation of future interactive articles,
        we have created ObservableHQ
        <img src="images/observable.svg" alt="ObservableHQ" width="20" height="20" style="position: relative; top: 3px">
        notebooks for each of the interactive visualizations here:
      </p>
        <ul>
          <li><a href="https://observablehq.com/@ameyasd/neighbourhoods-for-cnns-and-gnns">Neighbourhood Definitions for CNNs and GNNs</a></li>
          <li><a href="https://observablehq.com/@ameyasd/cleaner-interactive-graph-polynomial-convolutions">Graph Polynomial Convolutions on a Grid</a></li>
          <li><a href="https://observablehq.com/@ameyasd/updated-chebnet-equations">Graph Polynomial Convolutions: Equations</a></li>
          <li><a href="https://observablehq.com/@ameyasd/interactive-gnn-equations">Modern Graph Neural Networks: Equations</a></li>
          <li>
            <a href="https://observablehq.com/@ameyasd/interactive-gnn-visualizations">Modern Graph Neural Networks: Interactive Models</a>
            which pulls together the following standalone notebooks:
            <ul>
              <li><a href="https://observablehq.com/@ameyasd/graph-convolutional-networks">Graph Convolutional Networks</a></li>
              <li><a href="https://observablehq.com/@ameyasd/graph-attention-networks">Graph Attention Networks</a></li>
              <li><a href="https://observablehq.com/@ameyasd/graph-sample-and-aggregate-graphsage">GraphSAGE</a></li>
              <li><a href="https://observablehq.com/@ameyasd/graph-isomorphism-networks">Graph Isomorphism Networks</a></li>
            </ul>
          </li>
          <li><a href="https://observablehq.com/@ameyasd/interactive-spectral-conversions">Laplacian Eigenvectors for Grids</a></li>
          <li><a href="https://observablehq.com/@ameyasd/spectral-decompositions-of-natural-images">Spectral Decomposition of Natural Images</a></li>
          <li><a href="https://observablehq.com/@ameyasd/spectral-convolutions-equation">Spectral Convolutions: Equations</a></li>
          <!-- <li><a href="https://observablehq.com/@ameyasd/the-game-of-life">The Game of Life</a></li> -->
        </ul>

  </d-article>


  <d-appendix id="appendix">
    
    <d-footnote-list></d-footnote-list>

    <!-- <h3 id="minimal-models">Appendix: Minimal Models for The Game of Life</h3>
    <p>
      We use a variant of the GCN that doesn't normalize by neighbour degrees, and has an additional constant bias term $C$:
      <d-math block>
        h_v' = f\left(W \cdot \sum_{u \in \mathcal{N}(v)} h_u + B \cdot h_v + C \right).
      </d-math>
      This variant can capture the optimal update rule with only a few parameters (henceforth, the 'minimal' GCN model, although there may
      be modifications to make this architecture even smaller):
    </p>
      <ul>
        <li>GCNConv:
          <d-math block>
              W = \begin{bmatrix} 1 \\ 1 \end{bmatrix} \qquad
              B = \begin{bmatrix} \frac{1}{10} \\ 1 \end{bmatrix} \qquad
              C = \begin{bmatrix} -3 \\ -2 \end{bmatrix} \qquad 
              f \equiv \text{identity}.
          </d-math>
        </li>
        <li>Linear:
          <d-math block>
              w = \begin{bmatrix} -10 & 1 \end{bmatrix} \qquad
              b = \begin{bmatrix} 0 \end{bmatrix}.
          </d-math>
        </li>
        <li>Linear:
          (This layer is necessary only for overparametrization factor $(m) > 1$,
          as it serves as a projection down to $2$-dimensions.)
          <d-math block>
              w = \begin{bmatrix} -1 \\ 1 \end{bmatrix} \qquad
              b = \begin{bmatrix} 1 \\ 0 \end{bmatrix}.
          </d-math>
        </li>
      </ul>
    <p>
      Unlike <d-cite key='game-of-life-nns'></d-cite>, we use ReLU activations exclusively, for consistency.
      With this, the 'minimal' CNN model is slightly different:
    </p>
      <ul>
        <li>GCNConv:
          <d-math block>
              w_1 = \begin{bmatrix} 1 & 1 & 1 \\ 1 & \frac{1}{10} & 1 \\ 1 & 1 & 1 \end{bmatrix} \qquad
              b_1 = -3 \qquad
              w_2 = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix} \qquad
              b_2 = -2.
          </d-math>
        </li>
        <li>Linear:
          <d-math block>
              w = \begin{bmatrix} -10 & 1 \end{bmatrix} \qquad
              b = \begin{bmatrix} 0 \end{bmatrix}.
          </d-math>
        </li>
        <li>Linear:
          (As before, and similar to <d-cite key='game-of-life-nns'></d-cite>, this layer is necessary only for overparametrization factor $(m) > 1$.)
          <d-math block>
              w = \begin{bmatrix} -1 \\ 1 \end{bmatrix} \qquad
              b = \begin{bmatrix} 1 \\ 0 \end{bmatrix}.
          </d-math>
        </li>
      </ul>
    <p>
      The variant described earlier in the article needs many more parameters to capture the optimal update rule on finite grids,
      since it would need to distinguish between non-central cells which have fewer neighbours.
      However, in an infinite grid, it would be able to capture the optimal update rule with only a few parameters,
      since all cells would have $7$ neighbours.
    </p>

    <h3 id="game-of-life-details">Appendix: The Game of Life Experiment Details </h3>
    <p>
      We generate $32 \times 5 = 160$ unique grids by varying the number of alive cells from 1 to 32, and randomly creating $5$ grids with the required number of alive cells.
      Then, we repeat these grids $2500$ times, shuffle the entire set of $160 \times 2500$ grids and batch them into $8000$ batches of $50$ grids each.
      Over each of these grids, $25\%$ of these cells are marked as 'training', while $25\%$ of them are marked as 'validation'.
      This is significantly lesser than the amount of training data used in <d-cite key='game-of-life-nns'></d-cite>.
    </p>
    <p>
      At each step, a training batch is fed in, and the categorical cross-entropy loss is computed over all of the 'training' cells in the batch,
      to update the weights of each model via stochastic gradient descent.
      Additionally, the categorical cross-entropy loss is computed over the 'validation' cells, and is tracked over the last $300$ steps.
      If the 'validation' loss hasn't improved over its value $300$ steps ago, the training procedure stops ('early-stopping').
    </p>
    <p>
      For each value of the overparametrization factor $m$ from $1$ to $10$, we train $40$ GCN and $40$ CNN models, each initialized differently (according to a random seed).
      Across all of these, only $2$ models went through all $8000$ training steps, and both of them had perfect validation accuracy.
    </p>
    <p>
      For completeness, we list the best and worst seeds (according to the validation accuracy after training) for each value of the overparametrization factor $m$.
      If multiple seeds had the same final validation accuracy, the largest seed (in numeric value) was chosen.
    </p>
      <table>
        <caption>GCN Seeds</caption>
        <thead>
          <tr><th>$m$</th><th>Best Seed</th><th>Worst Seed</th></tr>
        </thead>
        <tbody>
          <tr><td>1</td><td>1</td><td>25</td></tr>
          <tr><td>2</td><td>13</td><td>31</td></tr>
          <tr><td>3</td><td>29</td><td>5</td></tr>
          <tr><td>4</td><td>0</td><td>13</td></tr>
          <tr><td>5</td><td>39</td><td>25</td></tr>
          <tr><td>6</td><td>39</td><td>3</td></tr>
          <tr><td>7</td><td>39</td><td>32</td></tr>
          <tr><td>8</td><td>39</td><td>17</td></tr>
          <tr><td>9</td><td>39</td><td>5</td></tr>
          <tr><td>10</td><td>39</td><td>0</td></tr>
        </tbody>
      </table>
      <table>
        <caption>CNN Seeds</caption>
        <thead>
          <tr><th>$m$</th><th>Best Seed</th><th>Worst Seed</th></tr>
        </thead>
        <tbody>
          <tr><td>1</td><td>25</td><td>24</td></tr>
          <tr><td>2</td><td>37</td><td>11</td></tr>
          <tr><td>3</td><td>19</td><td>4</td></tr>
          <tr><td>4</td><td>19</td><td>21</td></tr>
          <tr><td>5</td><td>39</td><td>8</td></tr>
          <tr><td>6</td><td>39</td><td>17</td></tr>
          <tr><td>7</td><td>39</td><td>30</td></tr>
          <tr><td>8</td><td>39</td><td>13</td></tr>
          <tr><td>9</td><td>39</td><td>30</td></tr>
          <tr><td>10</td><td>39</td><td>34</td></tr>
        </tbody>
      </table>
    <p>
      Links to all of this code are available in the <a href="#supplementary">Supplementary Material</a>.
    </p> -->
    <!-- XManager Experiment ID: 19174057 -->

    <h3>Acknowledgments</h3>
    <p>
      We are deeply grateful to <a href="https://observablehq.com">ObservableHQ</a>, a wonderful platform for developing interactive visualizations.
      The static visualizations would not have been possible without <a href="https://inkscape.org/">Inkscape</a>
      and Alexander Lenail's <a href="https://alexlenail.me/NN-SVG/index.html">Neural Network SVG Generator</a>.
      The molecule diagrams depicted above were obtained and modified from
      <a href="https://commons.wikimedia.org/wiki/File:Caramboxin.svg">Wikimedia Commons</a>,
      available in the public domain.
    </p>
    <p>
      We would like to acknowledge the following Distill articles for inspiration on article design:
    </p>
      <ul>
        <li><a href="https://distill.pub/2019/memorization-in-rnns/">Visualizing memorization in RNNs</a></li>
        <li><a href="https://distill.pub/2020/understanding-rl-vision/">Understanding RL Vision</a></li>
      </ul>
    <p>
      We would like to thank Thomas Kipf for his valuable feedback on the technical content within this article.
    </p>
    <p>
      We would like to thank David Nichols for creating <a href="https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40">Coloring for Colorblindness</a>
      which helped us improve the accessibility of this article's color scheme.
    </p>
    <p>
      We would also like to acknowledge <a href="http://web.stanford.edu/class/cs224w/">CS224W: Machine Learning with Graphs</a> as an excellent reference from which the authors benefitted significantly.
    </p>
    <p>
      Ashish Tendulkar from Google Research India provided significant feedback on the content within this article, helping its readability.
      He also helped with identifying the topics this article should cover, and with brainstorming the experiments here.
    </p>
    <p>
      Adam Pearce from Google Research helped us immensely with article hosting and rendering.
    </p>
    <p>
      Finally, we would like to thank Anirban Santara, Sujoy Paul and Ansh Khurana from Google Research India for their help with setting up and running experiments.
    </p>

    <h3>Author Contributions</h3>
    <p>
      <b>Ameya Daigavane</b> drafted most of the text, designed experiments and created the interactive visualizations in this article.
      <b>Balaraman Ravindran</b> and <b>Gaurav Aggarwal</b> extensively guided the overall direction of the article,
      deliberated over the design and scope of experiments, provided much feedback on the interactive visualizations,
      edited the text, and described improvements to make the article more accessible to readers.
    </p>

    <h3>Discussion and Review</h3>
    <p>
      <a href="https://github.com/distillpub/exploring-graph-nns/issues/1">Review 1 - Chaitanya K. Joshi</a><br>
      <a href="https://github.com/distillpub/exploring-graph-nns/issues/2">Review 2 - Nick Moran</a><br>
      <a href="https://github.com/distillpub/exploring-graph-nns/issues/3">Review 3 - Anonymous</a><br>
    </p>

    <d-citation-list></d-citation-list>
  </d-appendix>

  <!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
  <d-bibliography src="bibliography.bib"></d-bibliography>

<script type="text/javascript" src="index.bundle.js"></script></body>
</html>